{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e017983",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07fb035",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../\u001b[0m\r\n",
      "├── \u001b[01;34mdataset\u001b[0m\r\n",
      "│   ├── \u001b[01;34mIMAGES\u001b[0m\r\n",
      "│   ├── \u001b[01;34moriginal_zip_file\u001b[0m\r\n",
      "│   └── \u001b[01;34mtfrecord\u001b[0m\r\n",
      "└── \u001b[01;34mscript\u001b[0m\r\n",
      "    └── \u001b[01;34m__pycache__\u001b[0m\r\n",
      "\r\n",
      "6 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5eb7b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7225ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 추후 Aguumentation을 위한 albumentations \n",
    "transforms = A.Compose([   \n",
    "                            A.Normalize( mean = ( 0.485, 0.456, 0.406) , \n",
    "                                         std = (0.229, 0.224, 0.225) )\n",
    "        ])\n",
    "\n",
    "val_transforms = A.Compose([   \n",
    "                            A.Normalize( mean = (  0.485, 0.456, 0.406) , \n",
    "                                         std = (0.229, 0.224, 0.225) )\n",
    "        ])\n",
    "\n",
    "def aug_fn(image ):\n",
    "    data = {\"image\":image}\n",
    "    aug_data = transforms(**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    return aug_img\n",
    "\n",
    "def process_data(image, label):\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "    return aug_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8ec0a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, transforms , mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.fold = fold\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        \n",
    "        ## fold값과 file_name을 불러오기위한 csv\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        \n",
    "        ## train set과 val set 나누기\n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "        \n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    ## csv파일을 통해 mini-batch data를 가져옴\n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['image_id']\n",
    "            \n",
    "            image = cv2.imread(f'../dataset/IMAGES/{file_name}')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size)) / 255.\n",
    "            \n",
    "            ## transform\n",
    "            image , label = process_data(image , r['target'])\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    ## 한 epoch돌때마다 shuffle\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f708048",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0532e07e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = '../dataset/data_label.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size=128, \n",
    "    csv_path=csv_path,\n",
    "    image_size=299,\n",
    "    mode='train',\n",
    "    shuffle=True, \n",
    "    fold = 3 , \n",
    "    transforms = transforms\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    batch_size=128, \n",
    "    csv_path=csv_path,\n",
    "    image_size=299,\n",
    "    mode='val',\n",
    "    shuffle=False , \n",
    "    fold = 3 , \n",
    "        transforms = val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 10:37:59.872510: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8043077],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444]],\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8043077],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0356455, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1178367, -2.0356455, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1177697, -2.0355768, -1.8043077],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444]],\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444]]],\n",
       " \n",
       " \n",
       "        [[[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.1178367, -2.0355082, -1.8043077]],\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1178367, -2.0355082, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.1178367, -2.0355082, -1.8043077]],\n",
       " \n",
       "         [[-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ]],\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ],\n",
       "          [-2.1178367, -2.0356455, -1.804376 ]]],\n",
       " \n",
       " \n",
       "        [[[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.1177025, -2.0355768, -1.8042394],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ]],\n",
       " \n",
       "         [[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.1176353, -2.0355768, -1.804171 ]],\n",
       " \n",
       "         [[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177697, -2.0357141, -1.8043077]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          ...,\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1177697, -2.0357141, -1.8043077]],\n",
       " \n",
       "         [[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1175683, -2.0355082, -1.8041027]],\n",
       " \n",
       "         [[-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          ...,\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-2.1178367, -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.1174338, -2.0355082, -1.8039659],\n",
       "          [-2.1176353, -2.0355082, -1.8041027],\n",
       "          [-2.1172323, -2.0356455, -1.8041027]],\n",
       " \n",
       "         [[-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1174338, -2.0355768, -1.8042394],\n",
       "          [-2.1174338, -2.0356455, -1.8042394],\n",
       "          [-2.1175683, -2.0355768, -1.8040342]],\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1177025, -2.0355082, -1.8042394],\n",
       "          [-2.1177697, -2.0355082, -1.804171 ],\n",
       "          [-2.117501 , -2.0355768, -1.8038292]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1177025, -2.0355768, -1.804171 ],\n",
       "          [-2.1177025, -2.0356455, -1.8040342],\n",
       "          [-2.1176353, -2.0356455, -1.8039659]],\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0355768, -1.8041027],\n",
       "          [-2.1178367, -2.0356455, -1.8041027],\n",
       "          [-2.1175683, -2.0353708, -1.8043077]],\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0355082, -1.804171 ],\n",
       "          [-2.1177697, -2.0356455, -1.8039659],\n",
       "          [-2.1177697, -2.0354395, -1.8042394]]],\n",
       " \n",
       " \n",
       "        [[[-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.1178367, -2.0355082, -1.8044444],\n",
       "          [-2.1178367, -2.0355082, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.1178367, -2.0355082, -1.8044444],\n",
       "          [-2.1178367, -2.0355082, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0356455, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.804376 ],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444],\n",
       "          [-2.117904 , -2.0355768, -1.8044444]]],\n",
       " \n",
       " \n",
       "        [[[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1177025, -2.0356455, -1.8042394],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         [[-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ]],\n",
       " \n",
       "         [[-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          ...,\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.117904 , -2.0357141, -1.8044444]],\n",
       " \n",
       "         [[-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1178367, -2.0357141, -1.804376 ],\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          ...,\n",
       "          [-2.1177697, -2.0357141, -1.8043077],\n",
       "          [-2.117904 , -2.0357141, -1.8044444],\n",
       "          [-2.1177697, -2.0357141, -1.8043077]]]], dtype=float32),\n",
       " array([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_generator\n",
    "          ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6c475",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327e3da4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input , Dense , concatenate , Conv2D , MaxPooling2D , BatchNormalization , ReLU , GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model , Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Flatten , Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abac52d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InceptionV3(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(InceptionV3 , self).__init__()\n",
    "        self.model = tf.keras.applications.InceptionV3(\n",
    "                                                    include_top=False,\n",
    "                                                    weights=\"imagenet\",\n",
    "                                                    input_tensor=None,\n",
    "                                                    input_shape=(299, 299 , 3),\n",
    "                                                    pooling=None,\n",
    "                                                    classes=1000,\n",
    "                                                    classifier_activation=\"softmax\",\n",
    "                                                  )\n",
    "        self.classifier = keras.Sequential([\n",
    "                                            GlobalAveragePooling2D(),\n",
    "                                            Dropout(0.5) , \n",
    "                                            Dense(2 , activation= 'softmax' , name = 'output')\n",
    "                                            ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.model(inputs)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self , input_shape):\n",
    "        inputs = Input(input_shape)\n",
    "        Model(inputs, self.call(inputs)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c34bd0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 00:14:44.613706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-07 00:14:44.964163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 242 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 21,772,450\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3()\n",
    "model.summary((299, 299 , 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb32e89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 학습 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e22e557",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD( )\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean()\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af783e63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff58659f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images , labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images , training = True)\n",
    "#         pred = tf.squeeze(pred)\n",
    "        # 손실\n",
    "        loss = loss_function(labels , pred)\n",
    "    \n",
    "    #미분 계산\n",
    "    gradients = tape.gradient(loss , model.trainable_weights)\n",
    "    \n",
    "    #optimizer\n",
    "    optimizer.apply_gradients(zip(gradients , model.trainable_weights) )\n",
    "    \n",
    "    ## loss값 계산\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels , pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec80ecd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(images , labels):\n",
    "    pred = model(images , training= False)\n",
    "#     pred =tf.squeeze(pred)\n",
    "    #손실\n",
    "    loss = loss_function(labels , pred)\n",
    "    \n",
    "    ## loss값 계산\n",
    "    val_loss(loss)\n",
    "    val_accuracy(labels , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6db78679",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_3488443/149747007.py\", line 7, in train_step  *\n        loss = loss_function(labels , pred)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (128,) and (128, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i , (images , labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_generator):\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images , labels \u001b[38;5;129;01min\u001b[39;00m val_generator:\n\u001b[1;32m      8\u001b[0m         val_step(images , labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filed6_dx67m.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     11\u001b[0m     pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model), (ag__\u001b[38;5;241m.\u001b[39mld(images),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(loss_function), (ag__\u001b[38;5;241m.\u001b[39mld(labels), ag__\u001b[38;5;241m.\u001b[39mld(pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_weights), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(optimizer)\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_weights), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/losses.py:139\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m   call_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 139\u001b[0m losses \u001b[38;5;241m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses_utils\u001b[38;5;241m.\u001b[39mcompute_weighted_loss(\n\u001b[1;32m    141\u001b[0m     losses, sample_weight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reduction())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/losses.py:243\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    240\u001b[0m   y_pred, y_true \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39msqueeze_or_expand_dimensions(y_pred, y_true)\n\u001b[1;32m    242\u001b[0m ag_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mag_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/losses.py:1787\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1782\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m (label_smoothing \u001b[38;5;241m/\u001b[39m num_classes)\n\u001b[1;32m   1784\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(label_smoothing, _smooth_labels,\n\u001b[1;32m   1785\u001b[0m                                \u001b[38;5;28;01mlambda\u001b[39;00m: y_true)\n\u001b[0;32m-> 1787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/backend.py:5119\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5117\u001b[0m target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(target)\n\u001b[1;32m   5118\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m-> 5119\u001b[0m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;66;03m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;66;03m# activations cache logits on the `output` Tensor.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(output, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_logits\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_3488443/149747007.py\", line 7, in train_step  *\n        loss = loss_function(labels , pred)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/user304/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (128,) and (128, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "for epoch in range(50):\n",
    "    \n",
    "    for i , (images , labels) in enumerate(train_generator):\n",
    "        train_step(images , labels)\n",
    "        \n",
    "    for images , labels in val_generator:\n",
    "        val_step(images , labels)\n",
    "        \n",
    "    template = 'epoch: {} , loss: {:.3f} , acc: {:.3f} , val_loss: {:.3f} , vall_acc : {:.3f}'\n",
    "    print(template.format(epoch+1 , train_loss.result() , train_accuracy.result() * 100 , \n",
    "                           val_loss.result() , val_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20babfb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "epoch: 1 , loss: 0.024 , acc: 99.040 , val_loss: 0.703 , vall_acc : 80.412\n",
      "epoch: 2 , loss: 0.024 , acc: 99.048 , val_loss: 0.703 , vall_acc : 80.451\n",
      "epoch: 3 , loss: 0.024 , acc: 99.055 , val_loss: 0.702 , vall_acc : 80.490\n",
      "epoch: 4 , loss: 0.024 , acc: 99.063 , val_loss: 0.702 , vall_acc : 80.528\n",
      "epoch: 5 , loss: 0.024 , acc: 99.071 , val_loss: 0.702 , vall_acc : 80.565\n",
      "epoch: 6 , loss: 0.024 , acc: 99.078 , val_loss: 0.702 , vall_acc : 80.604\n",
      "epoch: 7 , loss: 0.023 , acc: 99.085 , val_loss: 0.702 , vall_acc : 80.642\n",
      "epoch: 8 , loss: 0.023 , acc: 99.093 , val_loss: 0.702 , vall_acc : 80.675\n",
      "epoch: 9 , loss: 0.023 , acc: 99.100 , val_loss: 0.702 , vall_acc : 80.708\n",
      "epoch: 10 , loss: 0.023 , acc: 99.107 , val_loss: 0.701 , vall_acc : 80.742\n",
      "epoch: 11 , loss: 0.023 , acc: 99.114 , val_loss: 0.701 , vall_acc : 80.773\n",
      "epoch: 12 , loss: 0.022 , acc: 99.120 , val_loss: 0.701 , vall_acc : 80.804\n",
      "epoch: 13 , loss: 0.022 , acc: 99.127 , val_loss: 0.701 , vall_acc : 80.839\n",
      "epoch: 14 , loss: 0.022 , acc: 99.134 , val_loss: 0.701 , vall_acc : 80.872\n",
      "epoch: 15 , loss: 0.022 , acc: 99.140 , val_loss: 0.701 , vall_acc : 80.906\n",
      "epoch: 16 , loss: 0.022 , acc: 99.147 , val_loss: 0.701 , vall_acc : 80.939\n",
      "epoch: 17 , loss: 0.022 , acc: 99.153 , val_loss: 0.701 , vall_acc : 80.968\n",
      "epoch: 18 , loss: 0.021 , acc: 99.159 , val_loss: 0.701 , vall_acc : 80.998\n",
      "epoch: 19 , loss: 0.021 , acc: 99.165 , val_loss: 0.701 , vall_acc : 81.028\n",
      "epoch: 20 , loss: 0.021 , acc: 99.171 , val_loss: 0.701 , vall_acc : 81.058\n",
      "epoch: 21 , loss: 0.021 , acc: 99.177 , val_loss: 0.701 , vall_acc : 81.085\n",
      "epoch: 22 , loss: 0.021 , acc: 99.183 , val_loss: 0.700 , vall_acc : 81.113\n",
      "epoch: 23 , loss: 0.021 , acc: 99.189 , val_loss: 0.700 , vall_acc : 81.142\n",
      "epoch: 24 , loss: 0.021 , acc: 99.194 , val_loss: 0.700 , vall_acc : 81.170\n",
      "epoch: 25 , loss: 0.020 , acc: 99.200 , val_loss: 0.700 , vall_acc : 81.199\n",
      "epoch: 26 , loss: 0.020 , acc: 99.206 , val_loss: 0.700 , vall_acc : 81.228\n",
      "epoch: 27 , loss: 0.020 , acc: 99.211 , val_loss: 0.700 , vall_acc : 81.257\n",
      "epoch: 28 , loss: 0.020 , acc: 99.216 , val_loss: 0.700 , vall_acc : 81.287\n",
      "epoch: 29 , loss: 0.020 , acc: 99.222 , val_loss: 0.700 , vall_acc : 81.317\n",
      "epoch: 30 , loss: 0.020 , acc: 99.227 , val_loss: 0.700 , vall_acc : 81.344\n",
      "epoch: 31 , loss: 0.020 , acc: 99.232 , val_loss: 0.700 , vall_acc : 81.370\n",
      "epoch: 32 , loss: 0.020 , acc: 99.237 , val_loss: 0.700 , vall_acc : 81.394\n",
      "epoch: 33 , loss: 0.019 , acc: 99.242 , val_loss: 0.700 , vall_acc : 81.423\n",
      "epoch: 34 , loss: 0.019 , acc: 99.247 , val_loss: 0.700 , vall_acc : 81.447\n",
      "epoch: 35 , loss: 0.019 , acc: 99.252 , val_loss: 0.700 , vall_acc : 81.473\n",
      "epoch: 36 , loss: 0.019 , acc: 99.257 , val_loss: 0.700 , vall_acc : 81.498\n",
      "epoch: 37 , loss: 0.019 , acc: 99.262 , val_loss: 0.700 , vall_acc : 81.520\n",
      "epoch: 38 , loss: 0.019 , acc: 99.266 , val_loss: 0.700 , vall_acc : 81.544\n",
      "epoch: 39 , loss: 0.019 , acc: 99.271 , val_loss: 0.700 , vall_acc : 81.569\n",
      "epoch: 40 , loss: 0.019 , acc: 99.276 , val_loss: 0.700 , vall_acc : 81.595\n",
      "epoch: 41 , loss: 0.018 , acc: 99.280 , val_loss: 0.700 , vall_acc : 81.619\n",
      "epoch: 42 , loss: 0.018 , acc: 99.285 , val_loss: 0.701 , vall_acc : 81.640\n",
      "epoch: 43 , loss: 0.018 , acc: 99.289 , val_loss: 0.701 , vall_acc : 81.664\n",
      "epoch: 44 , loss: 0.018 , acc: 99.293 , val_loss: 0.701 , vall_acc : 81.685\n",
      "epoch: 45 , loss: 0.018 , acc: 99.298 , val_loss: 0.701 , vall_acc : 81.706\n",
      "epoch: 46 , loss: 0.018 , acc: 99.302 , val_loss: 0.701 , vall_acc : 81.730\n",
      "epoch: 47 , loss: 0.018 , acc: 99.306 , val_loss: 0.701 , vall_acc : 81.754\n",
      "epoch: 48 , loss: 0.018 , acc: 99.310 , val_loss: 0.701 , vall_acc : 81.778\n",
      "epoch: 49 , loss: 0.018 , acc: 99.315 , val_loss: 0.701 , vall_acc : 81.799\n",
      "epoch: 50 , loss: 0.017 , acc: 99.319 , val_loss: 0.701 , vall_acc : 81.821\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "for epoch in range(50):\n",
    "    \n",
    "    for i , (images , labels) in enumerate(train_generator):\n",
    "        train_step(images , labels)\n",
    "        \n",
    "    for images , labels in val_generator:\n",
    "        val_step(images , labels)\n",
    "        \n",
    "    template = 'epoch: {} , loss: {:.3f} , acc: {:.3f} , val_loss: {:.3f} , vall_acc : {:.3f}'\n",
    "    print(template.format(epoch+1 , train_loss.result() , train_accuracy.result() * 100 , \n",
    "                           val_loss.result() , val_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb1303e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "label_list = []\n",
    "for images , labels in val_generator:\n",
    "    pred = model(images , training = False)\n",
    "    pred_list.extend(pred.numpy().tolist())\n",
    "    label_list.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07d090f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_list_test = np.array(pred_list).argmax(axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5e8484d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe6657d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242,  15],\n",
       "       [ 37,  55]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(label_list , pred_list_test  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb435e97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "167967e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(label_list , pred_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95899cca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5978260869565217"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(label_list , pred_list_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
